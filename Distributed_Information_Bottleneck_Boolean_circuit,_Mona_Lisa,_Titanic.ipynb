{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed Information Bottleneck -- Boolean circuit, Mona Lisa, Titanic",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSKcLuvKNVrd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This demo code accompanies \n",
        "\"The Distributed Information Bottleneck reveals the explanatory structure of complex systems\"\n",
        "Kieran A Murphy and Dani S Bassett\n",
        "\n",
        "https://arxiv.org/abs/2204.07576\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import scipy.ndimage as nim\n",
        "from google.colab import files\n",
        "\n",
        "tfkl = tf.keras.layers\n",
        "default_mpl_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']"
      ],
      "metadata": {
        "id": "UZ_VaCd-OAEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boolean circuit"
      ],
      "metadata": {
        "id": "lkWZuUnI4o5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In this first section, we approximate a 10-input, 1-output Boolean circuit.\n",
        "Because the input components may take only two values, the encoders are simple.\n",
        "They are just two trainable constants that provide the mean and variance of a \n",
        "distribution in representation space.\n",
        "'''"
      ],
      "metadata": {
        "id": "xoUH45rRBbFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gates = [np.logical_and, np.logical_or, np.logical_xor]\n",
        "\n",
        "# This is the circuit from the paper, formatted such that each intermediate output is defined by the contents of the brackets: [gate_id, input1, input2]\n",
        "circuit_specification = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, [1, 0, 1], [2, 8, 7], [0, 4, 3], [1, 11, 5], [2, 6, 12], [2, 13, 9], [1, 14, 10], [0, 15, 2], [0, 17, 16]]\n",
        "number_input_gates = 10\n",
        "\n",
        "def apply_gates(inputs):\n",
        "  intermed = inputs\n",
        "  for thing in circuit_specification[inputs.shape[-1]:]:\n",
        "    intermed = np.concatenate([intermed, np.int32(gates[thing[0]](intermed[:, thing[1]], intermed[:, thing[2]]))[:, np.newaxis]], -1)\n",
        "  return intermed\n",
        "\n",
        "def compute_entropy(vals):\n",
        "  probs = np.bincount(vals)/float(vals.shape[0])\n",
        "  probs = probs[probs>0]\n",
        "  return -np.sum(probs * np.log(probs))\n",
        "\n",
        "# Evaluate the full truth table\n",
        "possible_inputs = np.meshgrid(*[[0, 1]]*number_input_gates)\n",
        "possible_inputs = np.stack(possible_inputs, -1)\n",
        "possible_inputs = np.reshape(possible_inputs, [-1, number_input_gates])\n",
        "\n",
        "truth_table = apply_gates(possible_inputs)\n",
        "\n",
        "entropy_y = compute_entropy(truth_table[:, -1])\n",
        "print(f'Entropy of Y: {entropy_y/np.log(2):.3f} bits.')"
      ],
      "metadata": {
        "id": "I4YrXRYzCySA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# During pretraining \\beta is at its minimum value so that the bottleneck\n",
        "# is too weak to prevent finding the max-fidelity relationship\n",
        "number_pretraining_steps = 10**4\n",
        "# Then \\beta is increased logarithmically during the annealing stage\n",
        "number_annealing_steps = 2*10**5\n",
        "beta_start = 1e-4\n",
        "beta_end = 1e0\n",
        "batch_size = 512\n",
        "lr = 3e-4\n",
        "optimizer = tf.keras.optimizers.Adam(lr)\n",
        "cross_entropy_series, kl_divergence_series = [[] for _ in range(2)]\n",
        "beta_var = tf.Variable(beta_start, dtype=tf.float32, trainable=False)\n",
        "##############################################################################\n",
        "# Network creation\n",
        "# The encoders are trainable constants, taking each binary 0/1 to a normal\n",
        "# distribution in representation space with +-mu as the mean\n",
        "input_mus = tf.Variable(tf.ones(number_input_gates), dtype=tf.float32, trainable=True)\n",
        "input_logvars = tf.Variable(-3*tf.ones(number_input_gates), dtype=tf.float32, trainable=True)\n",
        "\n",
        "combined_encoder = tf.keras.Sequential([tfkl.Input((number_input_gates,)),\n",
        "                                        tfkl.Dense(256, 'relu'),\n",
        "                                        tfkl.Dense(256, 'relu'),\n",
        "                                        tfkl.Dense(256, 'relu'),\n",
        "                                        tfkl.Dense(1)])\n",
        "all_trainable_vars = combined_encoder.trainable_variables\n",
        "all_trainable_vars += [input_mus, input_logvars]\n",
        "    \n",
        "##############################################################################\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "@tf.function\n",
        "def train_step():\n",
        "  rand_samples = tf.random.categorical(tf.zeros((batch_size, truth_table.shape[0])), 1)\n",
        "  x = tf.gather(truth_table, rand_samples, axis=0)[:, 0, :number_input_gates]\n",
        "  y = tf.gather(truth_table, rand_samples, axis=0)[:, 0, -1]\n",
        "  x = tf.cast(x, tf.float32)\n",
        "  with tf.GradientTape() as tape:\n",
        "    x_channeled = tf.random.normal(x.shape, mean=input_mus*(x*2-1.), stddev=tf.exp(input_logvars/2.))\n",
        "    y_predicted = combined_encoder(x_channeled)\n",
        "    kl_divergence_channels = 0.5 * (tf.square(input_mus) + tf.exp(input_logvars) - input_logvars - 1.) # shape [num_spins]\n",
        "    cross_entropy = tf.reduce_mean(bce_loss(y, y_predicted))\n",
        "    loss = cross_entropy + beta_var*tf.reduce_sum(kl_divergence_channels)\n",
        "  grads = tape.gradient(loss, all_trainable_vars)\n",
        "  optimizer.apply_gradients(zip(grads, all_trainable_vars))\n",
        "  return cross_entropy, kl_divergence_channels\n",
        "\n",
        "for step in range(number_pretraining_steps+number_annealing_steps):\n",
        "  beta_var.assign(np.exp(np.log(beta_start)+float(max(step-number_pretraining_steps, 0))/number_annealing_steps*(np.log(beta_end)-np.log(beta_start))))\n",
        "  cross_entropy, kl_divergence_channels = train_step()\n",
        "  cross_entropy_series.append(cross_entropy.numpy())\n",
        "  kl_divergence_series.append(kl_divergence_channels.numpy())\n",
        "\n",
        "kl_divergence_series = np.stack(kl_divergence_series, 0)\n",
        "\n",
        "## Plot the error and KL divergences during the run\n",
        "beta_lims = [5e-3, 5e-1]\n",
        "likelihood_lims = [1e-3, None]\n",
        "kl_lims = [0, 1.75]\n",
        "plt.figure(figsize=(8, 4))\n",
        "ax = plt.gca()\n",
        "smoothing_sigma = 50\n",
        "betas = np.exp(np.log(beta_start)+np.linspace(0, 1, number_annealing_steps)*(np.log(beta_end)-np.log(beta_start)))\n",
        "ax.plot(betas, nim.filters.gaussian_filter1d(cross_entropy_series[-number_annealing_steps:], smoothing_sigma)/np.log(2), lw=3, color='k')\n",
        "\n",
        "ax2 = ax.twinx()\n",
        "[ax2.plot(betas, nim.filters.gaussian_filter1d(kl_divergence_series[-number_annealing_steps:, i], smoothing_sigma)/np.log(2), lw=3.5) for i in range(number_input_gates)]\n",
        "ax.plot([0, 1], [entropy_y/np.log(2)]*2, 'k:', lw=2)\n",
        "ax.set_ylabel('Cross entropy (bits)', color='k', fontsize=14)\n",
        "ax2.set_ylabel('KL Divergence (bits)', color='b', fontsize=14)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('Bottleneck strength beta', fontsize=14)\n",
        "ax.set_xlim(beta_lims)\n",
        "ax.set_ylim(likelihood_lims)\n",
        "ax2.set_ylim(kl_lims)\n",
        "\n",
        "ax.set_zorder(ax2.get_zorder()+1)\n",
        "ax.patch.set_visible(False)\n",
        "ax.tick_params(which='both', width=2, length=8, direction='in')\n",
        "ax2.tick_params(which='both', width=2, length=8, direction='in')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "679nXU-l4xJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mona Lisa"
      ],
      "metadata": {
        "id": "Xsp0cAnz4x8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Images are rich relationships between position and color.\n",
        "We use the Distributed IB to find an approximation scheme to Leonardo da Vinci's Mona Lisa.\n",
        "\n",
        "Rather than predicting a distribution over color and evaluating the cross entropy\n",
        "in color space, we operate in embedding space with the help of the InfoNCE loss.\n",
        "To optimize the InfoNCE contribution, each position-color pair should be co-located in a \n",
        "shared embedding space, with color embedded in its entirety and position embedded \n",
        "by its horizontal and vertical components independently before passing through a \n",
        "combined encoder as with the Boolean circuit.\n",
        "\n",
        "The degree to which the embedding space leads to consistent matches between a \n",
        "position and its correct color serves as a bound on the mutual information while \n",
        "letting us sidestep any manual discretization of color space.\n",
        "\n",
        "We display approximate relationships throughout training to visualize the gradual\n",
        "erosion of fidelity and the coarsening of block-like interactions between the horizontal\n",
        "and vertical components of the pixel position.\n",
        "'''"
      ],
      "metadata": {
        "id": "eT0vhUkHAxnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from wikipedia\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/6/6a/Mona_Lisa.jpg"
      ],
      "metadata": {
        "id": "Don41qR34xGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "fname = './Mona_Lisa.jpg'\n",
        "image = Image.open(fname)\n",
        "\n",
        "image = np.float32(np.asarray(image))/255.\n",
        "image = resize(image, (600, 400))\n",
        "plt.figure(figsize=(5, 8))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b0YwrXp15xpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Similarity functions for InfoNCE evaluation\n",
        "# Borrowed from https://github.com/google-research/google-research/tree/master/isolating_factors\n",
        "@tf.function\n",
        "def pairwise_l2_distance(pts1, pts2):\n",
        "  \"\"\"Computes squared L2 distances between each element of each set of points.\n",
        "  Args:\n",
        "    pts1: [N, d] tensor of points.\n",
        "    pts2: [M, d] tensor of points.\n",
        "  Returns:\n",
        "    distance_matrix: [N, M] tensor of distances.\n",
        "  \"\"\"\n",
        "  norm1 = tf.reduce_sum(tf.square(pts1), axis=1, keepdims=True)\n",
        "  norm2 = tf.reduce_sum(tf.square(pts2), axis=1)\n",
        "  norm2 = tf.reshape(norm2, [1, -1])\n",
        "  distance_matrix = tf.maximum(\n",
        "      norm1 + norm2 - 2.0 * tf.matmul(pts1, pts2, transpose_b=True), 0.0)\n",
        "  return distance_matrix\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def pairwise_l1_distance(pts1, pts2):\n",
        "  \"\"\"Computes L1 distances between each element of each set of points.\n",
        "  Args:\n",
        "    pts1: [N, d] tensor of points.\n",
        "    pts2: [M, d] tensor of points.\n",
        "  Returns:\n",
        "    distance_matrix: [N, M] tensor of distances.\n",
        "  \"\"\"\n",
        "  stack_size2 = pts2.shape[0]\n",
        "  pts1_tiled = tf.tile(tf.expand_dims(pts1, 1), [1, stack_size2, 1])\n",
        "  distance_matrix = tf.reduce_sum(tf.abs(pts1_tiled-pts2), -1)\n",
        "  return distance_matrix\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def pairwise_linf_distance(pts1, pts2):\n",
        "  \"\"\"Computes Chebyshev distances between each element of each set of points.\n",
        "  The Chebyshev/chessboard distance is the L_infinity distance between two\n",
        "  points, the maximum difference between any of their dimensions.\n",
        "  Args:\n",
        "    pts1: [N, d] tensor of points.\n",
        "    pts2: [M, d] tensor of points.\n",
        "  Returns:\n",
        "    distance_matrix: [N, M] tensor of distances.\n",
        "  \"\"\"\n",
        "  stack_size2 = pts2.shape[0]\n",
        "  pts1_tiled = tf.tile(tf.expand_dims(pts1, 1), [1, stack_size2, 1])\n",
        "  distance_matrix = tf.reduce_max(tf.abs(pts1_tiled-pts2), -1)\n",
        "  return distance_matrix\n",
        "\n",
        "\n",
        "def get_scaled_similarity(embeddings1,\n",
        "                          embeddings2,\n",
        "                          similarity_type,\n",
        "                          temperature):\n",
        "  \"\"\"Returns matrix of similarities between two sets of embeddings.\n",
        "  Similarity is a scalar relating two embeddings, such that a more similar pair\n",
        "  of embeddings has a higher value of similarity than a less similar pair.  This\n",
        "  is intentionally vague to emphasize the freedom in defining measures of\n",
        "  similarity. For the similarities defined, the distance-related ones range from\n",
        "  -inf to 0 and cosine similarity ranges from -1 to 1.\n",
        "  Args:\n",
        "    embeddings1: [N, d] float tensor of embeddings.\n",
        "    embeddings2: [M, d] float tensor of embeddings.\n",
        "    similarity_type: String with the method of computing similarity between\n",
        "      embeddings. Implemented:\n",
        "        l2sq -- Squared L2 (Euclidean) distance\n",
        "        l2 -- L2 (Euclidean) distance\n",
        "        l1 -- L1 (Manhattan) distance\n",
        "        linf -- L_inf (Chebyshev) distance\n",
        "        cosine -- Cosine similarity, the inner product of the normalized vectors\n",
        "    temperature: Float value which divides all similarity values, setting a\n",
        "      scale for the similarity values.  Should be positive.\n",
        "  Raises:\n",
        "    ValueError: If the similarity type is not recognized.\n",
        "  \"\"\"\n",
        "  eps = 1e-9\n",
        "  if similarity_type == 'l2sq':\n",
        "    similarity = -1.0 * pairwise_l2_distance(embeddings1, embeddings2)\n",
        "  elif similarity_type == 'l2':\n",
        "    # Add a small value eps in the square root so that the gradient is always\n",
        "    # with respect to a nonzero value.\n",
        "    similarity = -1.0 * tf.sqrt(\n",
        "        pairwise_l2_distance(embeddings1, embeddings2) + eps)\n",
        "  elif similarity_type == 'l1':\n",
        "    similarity = -1.0 * pairwise_l1_distance(embeddings1, embeddings2)\n",
        "  elif similarity_type == 'linf':\n",
        "    similarity = -1.0 * pairwise_linf_distance(embeddings1, embeddings2)\n",
        "  elif similarity_type == 'cosine':\n",
        "    embeddings1, _ = tf.linalg.normalize(embeddings1, ord=2, axis=-1)\n",
        "    embeddings2, _ = tf.linalg.normalize(embeddings2, ord=2, axis=-1)\n",
        "    similarity = tf.matmul(embeddings1, embeddings2, transpose_b=True)\n",
        "  else:\n",
        "    raise ValueError('Similarity type not implemented: ', similarity_type)\n",
        "\n",
        "  similarity /= temperature\n",
        "  return similarity"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1ZDryAnq6PWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional encoding helps with high frequency information in the image; \n",
        "# see Appendix A in the manuscript for more discussion\n",
        "number_positional_encoding_freqs = 10\n",
        "\n",
        "input_embedding_dim = 32\n",
        "shared_embedding_dim = 64\n",
        "encoder_spec = [512]*3\n",
        "decoder_spec = [128]*3\n",
        "activation_fn = 'relu'\n",
        "lr = 3e-4\n",
        "beta_start = 1e-6\n",
        "beta_end = 3e0\n",
        "number_pretraining_steps = 2*10**4\n",
        "number_annealing_steps = 10**5\n",
        "plot_every_n_steps = 1000\n",
        "batch_size = 2048\n",
        "\n",
        "## For the InfoNCE loss; other valid parameter values are discussed in the cell above\n",
        "similarity = 'l2'\n",
        "temperature = 1."
      ],
      "metadata": {
        "id": "8QMZR4ib6bGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set up the data and networks\n",
        "image_x, image_y, _ = image.shape\n",
        "aspect_ratio = float(image_y)/float(image_x)\n",
        "xx, yy = np.meshgrid(np.linspace(-aspect_ratio, aspect_ratio, image_y),\n",
        "                     np.linspace(-1, 1, image_x))\n",
        "\n",
        "positional_encoding_freqs = np.power(2., np.arange(1, number_positional_encoding_freqs))*np.pi\n",
        "\n",
        "inp_pts_train = np.stack([xx.reshape([-1]), yy.reshape([-1])], -1)\n",
        "outp_pts_train = image.reshape([-1, 3])\n",
        "\n",
        "number_input_channels = 2\n",
        "\n",
        "inp_pts_train = np.stack([inp_pts_train] + [np.sin(inp_pts_train*freq) for freq in positional_encoding_freqs], axis=-1).astype(np.float32)\n",
        "# 'Positionally' encode the RGB colors as well\n",
        "outp_pts_train = np.concatenate([outp_pts_train] + [np.sin(outp_pts_train*freq) for freq in positional_encoding_freqs], axis=-1)\n",
        "\n",
        "# This is to signify the different channels to the encoder so that we can get away with using a single encoder for all channels\n",
        "one_hot_appendix = tf.tile(tf.expand_dims(tf.eye(number_input_channels), 0), [batch_size, 1, 1])\n",
        "\n",
        "# To get a color out, take a random sampling of colors from the GT image and then paint by numbers\n",
        "palette_size = 1024\n",
        "color_palette_inds = np.random.choice(outp_pts_train.shape[0], size=palette_size, replace=False)\n",
        "color_palette = image.reshape([-1, 3])[color_palette_inds]\n",
        "\n",
        "input_encoder = tf.keras.Sequential([tfkl.Input(number_positional_encoding_freqs+number_input_channels)]+[tfkl.Dense(num_units, activation_fn) for num_units in encoder_spec]+[tfkl.Dense(input_embedding_dim)])\n",
        "combined_encoder = tf.keras.Sequential([tfkl.Input(number_input_channels*(input_embedding_dim//2),)]+[tfkl.Dense(num_units, activation_fn) for num_units in decoder_spec]+[tfkl.Dense(shared_embedding_dim)])  \n",
        "color_encoder = tf.keras.Sequential([tfkl.Input(3*number_positional_encoding_freqs,)]+[tfkl.Dense(num_units, activation_fn) for num_units in decoder_spec]+[tfkl.Dense(shared_embedding_dim)])\n",
        "all_trainable_vars = input_encoder.trainable_variables\n",
        "all_trainable_vars += combined_encoder.trainable_variables\n",
        "all_trainable_vars += color_encoder.trainable_variables\n",
        "\n",
        "beta_var = tf.Variable(beta_start, dtype=tf.float32, trainable=False)\n",
        "optimizer = tf.keras.optimizers.Adam(lr)"
      ],
      "metadata": {
        "id": "adGSHV5LZyRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xent_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "@tf.function\n",
        "def train_step(batch_inps, batch_outps):\n",
        "  x_inp = tf.concat([batch_inps, one_hot_appendix], -1)\n",
        "  x_inp = tf.reshape(x_inp, [batch_size*number_input_channels, -1])\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_mus, enc_logvars = tf.split(input_encoder(x_inp), 2, axis=-1)\n",
        "    all_embs = tf.random.normal(enc_mus.shape, mean=enc_mus, stddev=tf.exp(enc_logvars/2.))\n",
        "    all_embs = tf.reshape(all_embs, [batch_size, -1])  # this concatenates the two embeddings which were previously siloed\n",
        "\n",
        "    x_embs = combined_encoder(tf.concat(all_embs, -1))\n",
        "    # x_embs = tf.reshape(x_embs, [batch_size, -1])\n",
        "\n",
        "    y_embs = color_encoder(batch_outps)\n",
        "\n",
        "    similarity_matrix = get_scaled_similarity(x_embs, y_embs, similarity, temperature)\n",
        "    loss_infonce = tf.reduce_mean(xent_loss(tf.range(batch_size), similarity_matrix))\n",
        "    loss_infonce += tf.reduce_mean(xent_loss(tf.range(batch_size), tf.transpose(similarity_matrix)))\n",
        "\n",
        "    kl_divergence_channels = tf.reduce_sum(0.5 * (tf.square(enc_mus) + tf.exp(enc_logvars) - enc_logvars - 1.), axis=-1)\n",
        "    kl_divergence_channels = tf.reshape(kl_divergence_channels, [batch_size, -1])\n",
        "    kl_divergence_channels = tf.reduce_mean(kl_divergence_channels, 0)  # average across the batch; all that's left is a different term per axis\n",
        "\n",
        "    loss = loss_infonce + beta_var*tf.reduce_sum(kl_divergence_channels)\n",
        "  grads = tape.gradient(loss, all_trainable_vars)\n",
        "  optimizer.apply_gradients(zip(grads, all_trainable_vars))\n",
        "  return loss_infonce, kl_divergence_channels"
      ],
      "metadata": {
        "id": "Ul3rgapNZ6N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training\n",
        "infonce_series, kl_divergence_series = [[] for _ in range(2)]\n",
        "# This code displays outputs in groups of 10, one each <plot_every_n_steps> steps\n",
        "plot_ind = 1\n",
        "inches_per_subplot = 2\n",
        "plt.figure(figsize=(inches_per_subplot*10, inches_per_subplot*1.5))\n",
        "for step in range(number_pretraining_steps+number_annealing_steps):\n",
        "  beta_var.assign(np.exp(np.log(beta_start)+float(max(step-number_pretraining_steps, 0))/number_annealing_steps*(np.log(beta_end)-np.log(beta_start))))\n",
        "  batch_inds = np.random.choice(inp_pts_train.shape[0], size=batch_size)\n",
        "  batch_inps = inp_pts_train[batch_inds]\n",
        "  batch_outps = outp_pts_train[batch_inds]\n",
        "  \n",
        "  loss_infonce, kl_divergence_channels = train_step(batch_inps, batch_outps)\n",
        "\n",
        "  infonce_series.append(loss_infonce.numpy())\n",
        "  kl_divergence_series.append(kl_divergence_channels)\n",
        "  if (step % plot_every_n_steps == 0) and (step > number_pretraining_steps):\n",
        "    ## Display the current approximation\n",
        "    y_embs = color_encoder(outp_pts_train)\n",
        "    color_palette_embs = tf.gather(y_embs, color_palette_inds)\n",
        "\n",
        "    reconstructed_image = []\n",
        "    num_pix = inp_pts_train.shape[0]\n",
        "    # Chunk up the operations for memory\n",
        "    chunking = 8192\n",
        "    for pix_ind_start in range(0, num_pix, chunking):\n",
        "      chunk_size = min(num_pix, pix_ind_start+chunking) - pix_ind_start\n",
        "      one_hot_appendix_disp = tf.tile(tf.expand_dims(tf.eye(number_input_channels), 0), [chunk_size, 1, 1])\n",
        "      x_inp = tf.concat([inp_pts_train[pix_ind_start:pix_ind_start+chunk_size], one_hot_appendix_disp], -1)   ## [bs, num_axes, num_pos] + [bs, num_axes, num_axes]\n",
        "      x_inp = tf.reshape(x_inp, [chunk_size*number_input_channels, -1])\n",
        "      enc_mus, enc_logvars = tf.split(input_encoder(x_inp), 2, axis=-1)  ## This will be [bs*num_axes, dim]\n",
        "      all_embs = enc_mus\n",
        "      all_embs = tf.reshape(all_embs, [chunk_size, -1])\n",
        "\n",
        "      x_embs = combined_encoder(tf.concat(all_embs, -1))\n",
        "      x_embs = tf.reshape(x_embs, [chunk_size, -1])\n",
        "\n",
        "      sim_mat = get_scaled_similarity(x_embs, color_palette_embs, similarity, temperature)\n",
        "      color_numbers = np.argmax(sim_mat, axis=-1)\n",
        "      reconstructed_image.append(color_palette[color_numbers])\n",
        "\n",
        "    reconstructed_image = tf.concat(reconstructed_image, 0)\n",
        "    plt.subplot(1, 10, plot_ind)\n",
        "    plt.imshow(np.reshape(reconstructed_image, [image_x, image_y, 3]))\n",
        "    if plot_ind in [1, 6]:\n",
        "      plt.title(f'Beta={beta_var.value():5f}', fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plot_ind+=1\n",
        "    if plot_ind > 10:\n",
        "      plt.show()\n",
        "      plot_ind = 1\n",
        "      plt.figure(figsize=(inches_per_subplot*10, inches_per_subplot*1.5))\n",
        "plt.show() # in case the division got messed up\n",
        "# Display the evolution of the loss terms over the \\beta sweep\n",
        "infonce_series = np.stack(infonce_series, 0)\n",
        "kl_divergence_series = np.stack(kl_divergence_series, 0)\n",
        "betas = np.exp(np.log(beta_start)+np.linspace(0, 1, number_annealing_steps)*(np.log(beta_end)-np.log(beta_start)))\n",
        "beta_lims = [1e-3, 3]\n",
        "kl_lims = [1e-2, 8e1]\n",
        "smoothing_sigma = 100\n",
        "plt.figure(figsize=(6, 4))\n",
        "ax = plt.gca()\n",
        "ax.plot(betas[-number_annealing_steps:], nim.filters.gaussian_filter1d(infonce_series[-number_annealing_steps:], smoothing_sigma)/np.log(2), lw=4, color='k')\n",
        "ax2 = ax.twinx()\n",
        "[ax2.plot(betas[-number_annealing_steps:], nim.filters.gaussian_filter1d(kl_divergence_series[-number_annealing_steps:, i], smoothing_sigma)/np.log(2), lw=4, label=['Horizontal', 'Vertical'][i]) for i in range(number_input_channels)]\n",
        "ax2.legend(loc='upper left')\n",
        "ax.set_ylabel('InfoNCE (bits)', color='k', fontsize=14)\n",
        "ax2.set_ylabel('KL Divergence (bits)', color='b', fontsize=14)\n",
        "ax2.set_yscale('log')\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('Bottleneck strength beta', fontsize=14)\n",
        "plt.xlim(beta_lims)\n",
        "ax2.set_ylim(kl_lims)\n",
        "ax.tick_params(which='both', width=2, length=8, direction='in')\n",
        "ax2.tick_params(which='both', width=2, length=8, direction='in')\n",
        "ax.set_zorder(ax2.get_zorder()+1)\n",
        "ax.patch.set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q5csgdKT6bA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic dataset"
      ],
      "metadata": {
        "id": "C37RmsY34qlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finally, we seek insight into a noisy relationship with primarily \n",
        "categorical features: the Titanic dataset.\n",
        "'''"
      ],
      "metadata": {
        "id": "I1bvWuu4Fsa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dset = tfds.load('titanic', split='train')"
      ],
      "metadata": {
        "id": "-jP4T482OKSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Since the dataset is so small, just load everything manually\n",
        "features = []\n",
        "survived = []\n",
        "good_keys = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "for passenger in dset:\n",
        "  features.append([passenger[key].numpy() for key in good_keys])\n",
        "  survived.append(passenger['survived'])\n",
        "\n",
        "## Munge the data\n",
        "pclasses = tf.stack([tf.one_hot(passenger[0], 3) for passenger in features], 0)\n",
        "sexes = tf.stack([tf.one_hot(passenger[1], 2) for passenger in features], 0)\n",
        "ages = tf.stack([(lambda x: np.float32([1., 0.])*(x<0) + np.float32([0., np.log(np.abs(x))])*(x>0))(passenger[2]) for passenger in features], 0)\n",
        "sibsps = tf.stack([tf.one_hot(passenger[3], 7) for passenger in features], 0)\n",
        "parches = tf.stack([tf.one_hot(passenger[4], 8) for passenger in features], 0)\n",
        "fares = tf.stack([(lambda x: np.float32([1., 0., 0.])*(x<0) + np.float32([0., 1., 0.])*(x==0) + np.float32([0., 0., np.log(np.abs(x+1e-4))])*(x>0))(passenger[5]) for passenger in features], 0)\n",
        "embarkeds = tf.stack([tf.one_hot(passenger[6]+1, 4) for passenger in features], 0)\n",
        "surviveds = tf.stack(survived, 0)\n",
        "\n",
        "training_fraction = 0.9\n",
        "training_inds = np.random.choice(surviveds.shape[0], size=int(training_fraction*surviveds.shape[0]), replace=False)\n",
        "validation_inds = [i for i in range(surviveds.shape[0]) if i not in training_inds]"
      ],
      "metadata": {
        "id": "7t56yucJOPYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a separate encoder for each feature\n",
        "feature_embedding_dim = 8\n",
        "encoder_arch = [128, 128]\n",
        "activation_fn = 'tanh'\n",
        "input_dimensionalities = [3, 2, 2, 7, 8, 3, 4]  ## one for each feature being used\n",
        "number_features = len(input_dimensionalities)\n",
        "\n",
        "encoders = []\n",
        "for input_dimensionality in input_dimensionalities:\n",
        "  encoders.append(tf.keras.Sequential([tfkl.Input((input_dimensionality,))] + [tfkl.Dense(num_units, activation_fn) for num_units in encoder_arch] + [tfkl.Dense(2*feature_embedding_dim)]))\n",
        "\n",
        "combined_encoder = tf.keras.Sequential([tfkl.Input((number_features*feature_embedding_dim,)),\n",
        "                                         tfkl.Dense(128, 'tanh'),\n",
        "                                         tfkl.Dense(128, 'tanh'),\n",
        "                                         tfkl.Dense(1)])\n",
        "\n",
        "\n",
        "all_trainable_vars = combined_encoder.trainable_variables\n",
        "for network in encoders:\n",
        "  all_trainable_vars += network.trainable_variables"
      ],
      "metadata": {
        "id": "xoDrOn1S6xqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_pretraining_steps = 2*10**4\n",
        "number_annealing_steps = 10**5\n",
        "lr = 1e-3\n",
        "beta_start = 5e-5\n",
        "beta_end = 1e0\n",
        "batch_size = 128\n",
        "eval_every = 1000\n",
        "beta_var = tf.Variable(beta_start, dtype=tf.float32, trainable=False)\n",
        "\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(lr)\n",
        "@tf.function\n",
        "def train_step(features, target_var):\n",
        "  kl_divergence_channels = []\n",
        "  running_embs = []\n",
        "  with tf.GradientTape() as tape:\n",
        "    for i in range(number_features):\n",
        "      emb_mus, emb_logvars = tf.split(encoders[i](features[i]), 2, axis=-1)\n",
        "      emb_channeled = tf.random.normal(emb_mus.shape, mean=emb_mus, stddev=tf.exp(emb_logvars/2.))\n",
        "      running_embs.append(emb_channeled)\n",
        "      kl_divergence_channels.append(tf.reduce_mean(tf.reduce_sum(0.5 * (tf.square(emb_mus) + tf.exp(emb_logvars) - emb_logvars - 1.), axis=-1)))\n",
        "\n",
        "    prediction = combined_encoder(tf.concat(running_embs, -1))\n",
        "    cross_entropy = tf.reduce_mean(bce_loss(target_var, prediction))\n",
        "\n",
        "    loss = cross_entropy + beta_var*(tf.reduce_sum(kl_divergence_channels))\n",
        "  grads = tape.gradient(loss, all_trainable_vars)\n",
        "  optimizer.apply_gradients(zip(grads, all_trainable_vars))\n",
        "\n",
        "  return cross_entropy, kl_divergence_channels\n",
        "@tf.function\n",
        "def eval_validation(features, target_var):\n",
        "  kl_loss_terms = []\n",
        "  running_embs = []\n",
        "  for i in range(number_features):\n",
        "    emb_mus, _ = tf.split(encoders[i](features[i]), 2, axis=-1)\n",
        "    running_embs.append(emb_mus)\n",
        "  prediction = combined_encoder(tf.concat(running_embs, -1))\n",
        "  cross_entropy = tf.reduce_sum(bce_loss(target_var, prediction))\n",
        "  return cross_entropy\n",
        "\n",
        "betas_time_series = []\n",
        "cross_entropy_series, cross_entropy_series_validation, kl_divergence_series = [[] for _ in range(3)]\n",
        "\n",
        "for step in range(number_pretraining_steps+number_annealing_steps):\n",
        "  beta_var.assign(np.exp(np.log(beta_start)+float(max(step-number_pretraining_steps, 0))/number_annealing_steps*(np.log(beta_end)-np.log(beta_start))))\n",
        "\n",
        "  batch_inds = np.random.choice(training_inds, size=batch_size, replace=False)\n",
        "  cross_entropy, kl_divergence_channels = train_step([tf.gather(pclasses, batch_inds),\n",
        "                              tf.gather(sexes, batch_inds),\n",
        "                              tf.gather(ages, batch_inds),\n",
        "                              tf.gather(sibsps, batch_inds),\n",
        "                              tf.gather(parches, batch_inds),\n",
        "                              tf.gather(fares, batch_inds),\n",
        "                              tf.gather(embarkeds, batch_inds)],\n",
        "                              tf.gather(surviveds, batch_inds))\n",
        "\n",
        "  cross_entropy_series.append(cross_entropy.numpy())\n",
        "  kl_divergence_series.append(kl_divergence_channels)\n",
        "  if (step % eval_every) == 0 and (step >= number_pretraining_steps):\n",
        "    cross_entropy_series_validation.append(eval_validation([tf.gather(pclasses, validation_inds),\n",
        "                                            tf.gather(sexes, validation_inds),\n",
        "                                            tf.gather(ages, validation_inds),\n",
        "                                            tf.gather(sibsps, validation_inds),\n",
        "                                            tf.gather(parches, validation_inds),\n",
        "                                            tf.gather(fares, validation_inds),\n",
        "                                            tf.gather(embarkeds, validation_inds)],\n",
        "                                            tf.gather(surviveds, validation_inds)))\n",
        "\n",
        "betas = np.exp(np.log(beta_start)+np.linspace(0, 1, number_annealing_steps)*(np.log(beta_end)-np.log(beta_start)))\n",
        "kl_divergence_series = np.stack(kl_divergence_series, 1)\n",
        "beta_lims = [5e-3, 0.5]\n",
        "kl_lims = [0, 4e0]\n",
        "xent_lims = [0, 1]\n",
        "smoothing_sigma = 50\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = plt.gca()\n",
        "ax.plot(betas, nim.filters.gaussian_filter1d(cross_entropy_series[number_pretraining_steps:], smoothing_sigma), lw=4, label=\"Cross entropy, Train\", color='k')\n",
        "ax.plot(betas[::eval_every], cross_entropy_series_validation, lw=2, label=\"Cross entropy, Validation\", color='k')\n",
        "ax2 = ax.twinx()\n",
        "[ax2.plot(betas, nim.filters.gaussian_filter1d(kl_term[number_pretraining_steps:], smoothing_sigma), lw=2.5) for kl_term in kl_divergence_series]\n",
        "[ax2.plot(0, 0.5, lw=5, color=default_mpl_colors[i], label=label) for i, label in enumerate(['Passenger class', 'Sex', 'Age', 'Siblings/spouses', 'Parents/children', 'Fare', 'Location embarked'])]\n",
        "\n",
        "ax.set_ylabel('Cross entropy (bits)', color='k', fontsize=14)\n",
        "ax2.set_ylabel('KL Divergence (bits)', color='b', fontsize=14)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('Bottleneck strength beta', fontsize=14)\n",
        "ax2.set_ylim(kl_lims)\n",
        "ax.set_xlim(beta_lims)\n",
        "ax.set_ylim(xent_lims)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qk_jQLrY61Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_HfJI9_05Qpp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}